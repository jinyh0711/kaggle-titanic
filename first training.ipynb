{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore')\nimport re\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nfrom sklearn import tree\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.データを確認"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape, test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# トレーニングデータとテストデータを結合\nall_data = train_data.append(test_data, ignore_index=True, sort=True).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.欠損値を補完する"},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Embarkedを補完"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[all_data.Embarked.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[~all_data.Embarked.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embarked_mode = all_data.Embarked.dropna().mode().values\nembarked_mode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Embarkedの欠損値に最頻値'S'を入れる\nall_data.Embarked = all_data.Embarked.fillna(value=embarked_mode[0])\nall_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 年齢を補完"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 名前からタイトルを抽出\nall_data['title'] = all_data.Name.str.split(',').map(lambda x: x[1]).str.split('.').map(lambda x: x[0]).str.strip()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 年齢が欠損しているタイトル別の行数\nage_na_titles = all_data[all_data.Age.isnull()].title.value_counts()\nage_na_titles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 年齢が欠損しているtitleがMrで結婚している行数\nall_data[all_data.Age.isnull() & (all_data.SibSp >0) & (all_data.title == 'Mr')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[all_data.Age.isnull() & (all_data.SibSp == 0) & (all_data.Parch == 0) & (all_data.title == 'Mr')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 年齢が欠損していない欠損タイトル別の行数\nage_na_title_df = all_data[all_data.title.isin(list(age_na_titles.index))]\nage_na_title_df[~age_na_title_df.Age.isnull()].title.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nage_mean = age_na_title_df[~age_na_title_df.Age.isnull()].groupby('title').Age.mean().to_dict()\nage_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(4, 3))\ng = sns.FacetGrid(age_na_title_df, col=\"title\", hue='Survived')\ng.map(plt.hist, \"Age\")\nfor ax in g.axes[0]:\n    title = ax.get_title().split('=')[1].split()[0]\n    ax.axvline(age_mean[title], ls='--')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"#各titleのAge平均値をAge欠損値に追加する\nall_data.Name.str.split(',').map(lambda x: x[1]).str.split('.').map(lambda x: x[0]).value_counts()\nall_data.loc[all_data.Age.isna(), 'Age'] = all_data[all_data.Age.isna()].title.map(age_mean)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3 Fareを補完"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[all_data.Fare.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fareの欠損値にEmbarked=S & Pclass=3のFare中央値で補完する\nall_data[(all_data.Pclass == 3) & (all_data.Embarked == 'S') & (all_data.Parch == 0) & (all_data.SibSp == 0)]\nfare_median = all_data[(all_data.Pclass == 3) & (all_data.Embarked == 'S') & (all_data.Parch == 0) & (all_data.SibSp == 0)].Fare.dropna().median()\nfare_median","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#上のデータを見ると、74番目のBing, Mr. Lee、　1258番目のRiihivouri, Miss. Susanna Juhantytar Sanni\"\"と１２７３番目のRisien、　Mrs. Samuel (Emma)のFareが異常に高い、それでこの二つ名前について調べる\n# all_data[all_data.Name.str.contains('Risien') | all_data.Name.str.contains('Riihivouri') | all_data.Name.str.contains('Lee')]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1258番目のRiihivouri, Miss. Susanna Juhantytar Sanni\"\"は一人ですが、Fareはかなり高い、ネットで調べたらPanulaの近所ということで、Panulaの家族と一緒に登船、\n# all_data[all_data.Name.str.contains('Risien') | all_data.Name.str.contains('Riihivouri') | all_data.Name.str.contains('Panula') | all_data.Name.str.contains('Lee')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**　6/10 夜ここまで　**"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.loc[:, 'Fare'] = all_data.Fare.fillna(fare_median)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4 キャビンの欠損値"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cabinあり、なし特徴量を追加\nall_data['has_cabin'] = 1\nall_data.loc[all_data.Cabin.isna(), 'has_cabin'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ncombine = [all_data]\nfor train in combine: \n    all_data['Cabin_Lett'] = all_data['Cabin'].apply(lambda x: str(x)[0]) \n    all_data['Cabin_Lett'] = all_data['Cabin_Lett'].apply(lambda x: str(x)) \n    all_data['Cabin_Lett'] = np.where(\n        (all_data['Cabin_Lett']).isin(\n            [ 'F', 'E', 'D', 'C', 'B', 'A']\n        ),\n        all_data['Cabin_Lett'],\n        np.where(\n            (all_data['Cabin_Lett']).isin(\n                ['W', '4', '7', '6', 'L', '5', '8']\n            ), \n            '0',\n            '0')\n    )\ndel all_data['Cabin'] \nall_data['Cabin_Lett']=all_data['Cabin_Lett'].replace(\"A\",1).replace(\"B\",2).replace(\"C\",1).replace(\"0\",0).replace(\"D\",2).replace(\"E\",2).replace(\"F\",1)\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all_data['Cabin_Lett']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots()\ndata = all_data[~all_data['Survived'].isna()]\nx = data.has_cabin.unique().tolist()\ny_all = data.has_cabin.value_counts().values.tolist()\ny_survi = data.groupby('has_cabin').Survived.sum().values.tolist()\nlabels = x\n\nax.bar(x, y_all, tick_label=labels, label='died')\nax.bar(x, y_survi, label='survived')\nax.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.drop('Cabin',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cabinを削除\n#all_data.drop(axis=1, columns=['Cabin'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#nullでないCabinの頭文字を取る\n#cabin = all_data[~all_data.Cabin.isna()].Cabin\n#cabin.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reg = re.compile(r'^([A-Z])\\d*')\n#all_data['cabin_class'] = cabin.str.split(' ').map(lambda x: reg.match(x[0]).groups()[0])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2019/6/13**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#家族がいる欠損値を家族のメンバーのCabin頭文字で埋める\n#all_data[~all_data.cabin_class.isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fareが同じのグループのCabin頭文字は同じ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#同じ港から登船した客の頭文字titleごとに近いはず","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2－2　カテゴリ変数のエンコーディング"},{"metadata":{},"cell_type":"markdown","source":"1. Ticketを処理"},{"metadata":{},"cell_type":"markdown","source":"1.1 Ticketを数字とアルファベットが混ざるものに分離する"},{"metadata":{"trusted":true},"cell_type":"code","source":"number_ticket = all_data[all_data['Ticket'].str.match('\\d+')]\nnum_alpha_ticket = all_data[all_data['Ticket'].str.match('[A-Z]+.+')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.2 数字だけのチケットの分布を確認"},{"metadata":{"trusted":true},"cell_type":"code","source":"number_ticket['Ticket'] = number_ticket['Ticket'].astype(int)\nnumber_ticket['Ticket'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_ticket.sort_values('Ticket', inplace=True)\nplt.figure()\nplt.ylim(0, 3300000) \nplt.plot(number_ticket['Ticket'], '-o')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_ticket.sort_values('Ticket', inplace=True)\nplt.figure()\nplt.ylim(0, 500000) \nplt.plot(number_ticket['Ticket'], '-o')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = [1, 2, 3, 4, 5]\nnumber_ticket_group1 = number_ticket[number_ticket['Ticket'] <= 100000]\nnumber_ticket_group2 = number_ticket[(number_ticket['Ticket'] > 100000) & (number_ticket['Ticket'] < 200000)]\nnumber_ticket_group3 = number_ticket[(number_ticket['Ticket'] > 200000) & (number_ticket['Ticket'] < 300000)]\nnumber_ticket_group4 = number_ticket[(number_ticket['Ticket'] > 300000) & (number_ticket['Ticket'] < 400000)]\nnumber_ticket_group5 = number_ticket[number_ticket['Ticket'] > 3000000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = [number_ticket_group1['Survived'].mean(), number_ticket_group2['Survived'].mean(),\n     number_ticket_group3['Survived'].mean(), number_ticket_group4['Survived'].mean(),\n     number_ticket_group5['Survived'].mean()\n    ]\nplt.figure()\nplt.bar(x, y)\nplt.xlabel('ticket number')\nplt.ylabel('Survived')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.3アルファベットが入ったチケット "},{"metadata":{"trusted":true},"cell_type":"code","source":"num_alpha_ticket.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_alpha_ticket['Ticket'].str.split(' ').map(lambda x: x[0]).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A_ticket = num_alpha_ticket[num_alpha_ticket['Ticket'].str.match('A.+')]\nCA_ticket = num_alpha_ticket[num_alpha_ticket['Ticket'].str.match('C\\.*A\\.*.+')]\nPC_ticket = num_alpha_ticket[num_alpha_ticket['Ticket'].str.match('PC.+')]\nPP_ticket = num_alpha_ticket[num_alpha_ticket['Ticket'].str.match('PP.+')]\nSOTON_ticket = num_alpha_ticket[num_alpha_ticket['Ticket'].str.match('SOTON.+')]\nSTON_ticket = num_alpha_ticket[num_alpha_ticket['Ticket'].str.match('STON.+')]\nLINE_ticket = num_alpha_ticket[num_alpha_ticket['Ticket'].str.match('LINE.*')]\nFC_ticket = num_alpha_ticket[num_alpha_ticket['Ticket'].str.match('F\\.C\\.(C\\.)*.+')]\nW_ticket = num_alpha_ticket[num_alpha_ticket['Ticket'].str.match('W.+')]\nC_ticket = num_alpha_ticket[num_alpha_ticket['Ticket'].str.match('C.+')]\nSC_ticket = num_alpha_ticket[num_alpha_ticket['Ticket'].str.match('S(\\.)*C.+')]\nSO_ticket = num_alpha_ticket[num_alpha_ticket['Ticket'].str.match('S(\\.)*O.+')]\nother_ticket = num_alpha_ticket[\n    num_alpha_ticket['Ticket'].str.match(\n        '(Fa)*(P/PP)*(S\\.P)*(S\\.*W)*.+'\n    )\n]\nx = [i for i in range(1, 14)]\ny = [A_ticket['Survived'].mean(), CA_ticket['Survived'].mean(), PC_ticket['Survived'].mean()\n    ,PP_ticket['Survived'].mean(), SOTON_ticket['Survived'].mean(), STON_ticket['Survived'].mean()\n    ,LINE_ticket['Survived'].mean(), FC_ticket['Survived'].mean(), W_ticket['Survived'].mean()\n    ,C_ticket['Survived'].mean(), SC_ticket['Survived'].mean(), SO_ticket['Survived'].mean()\n    ,other_ticket['Survived'].mean()\n    ]\nplt.figure()\nplt.bar(x, y)\nplt.ylabel('survived')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W_ticket['Ticket'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_ticket.loc[number_ticket['Ticket'] <= 100000, 'Ticket'] = 14\nnumber_ticket.loc[(number_ticket['Ticket'] > 100000) & (number_ticket['Ticket'] <= 200000), 'Ticket'] = 15\nnumber_ticket.loc[(number_ticket['Ticket'] > 200000) & (number_ticket['Ticket'] <= 300000), 'Ticket'] = 13\nnumber_ticket.loc[(number_ticket['Ticket'] > 300000) & (number_ticket['Ticket'] <= 400000), 'Ticket'] = 5\nnumber_ticket.loc[number_ticket['Ticket'] > 3000000, 'Ticket'] = 6\nnum_alpha_ticket.loc[num_alpha_ticket['Ticket'].str.match('A.+'), 'Ticket'] = \"1\"\nnum_alpha_ticket.loc[num_alpha_ticket['Ticket'].str.match('C\\.*A\\.*.+'), 'Ticket'] = \"8\"\nnum_alpha_ticket.loc[num_alpha_ticket['Ticket'].str.match('PC.+'), 'Ticket'] = \"16\"\nnum_alpha_ticket.loc[num_alpha_ticket['Ticket'].str.match('PP.+'), 'Ticket'] = \"18\"\nnum_alpha_ticket.loc[num_alpha_ticket['Ticket'].str.match('SOTON.+'), 'Ticket'] = \"3\"\nnum_alpha_ticket.loc[num_alpha_ticket['Ticket'].str.match('STON.+'), 'Ticket'] = \"11\"\nnum_alpha_ticket.loc[num_alpha_ticket['Ticket'].str.match('LINE.*'), 'Ticket'] = \"7\"\nnum_alpha_ticket.loc[num_alpha_ticket['Ticket'].str.match('F\\.C\\.(C\\.)*.+'), 'Ticket'] = \"17\"\nnum_alpha_ticket.loc[num_alpha_ticket['Ticket'].str.match('W.+'), 'Ticket'] = \"4\"\nnum_alpha_ticket.loc[num_alpha_ticket['Ticket'].str.match('C.+'), 'Ticket'] = \"9\"\nnum_alpha_ticket.loc[num_alpha_ticket['Ticket'].str.match('S(\\.)*C.+'), 'Ticket'] = \"12\"\nnum_alpha_ticket.loc[num_alpha_ticket['Ticket'].str.match('S(\\.)*O.+'), 'Ticket'] = \"2\"\nnum_alpha_ticket.loc[num_alpha_ticket['Ticket'].str.match('[^\\d](Fa)*(P/PP)*(S\\.P)*(S\\.*W)*.+'), 'Ticket'] = \"10\"\nnum_alpha_ticket['Ticket'] = num_alpha_ticket['Ticket'].apply(lambda x: int(x))\nall_data = pd.concat([number_ticket, num_alpha_ticket])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fareの処理**"},{"metadata":{},"cell_type":"markdown","source":"1. PclassごとにFareが同じ人（家族、または知り合い）を見つける"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pclass=3のシングルFareの中央値\nfare_median_Pclass3 = all_data[(all_data.Pclass == 3)  & (all_data.Parch == 0) & (all_data.SibSp == 0)].Fare.dropna().median()\nfare_median_Pclass3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pclass=3の異常値を見つける\nfare_yijo_Pclass3 = all_data[(all_data.Fare > (fare_median_Pclass3*2)) & (all_data.Pclass == 3)] \nfare_yijo_Pclass3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pclass=２のシングルFareの中央値\nfare_median_Pclass2 = all_data[(all_data.Pclass == 2) & (all_data.Parch == 0) & (all_data.SibSp == 0)].Fare.dropna().median()\nfare_median_Pclass2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pclass=2の異常値を見つける\nfare_yijo_Pclass2 = all_data[(all_data.Fare > (fare_median_Pclass2*2)) & (all_data.Pclass == 2)] \nfare_yijo_Pclass2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pclass=１のシングルFareの中央値\nfare_median_Pclass1 = all_data[(all_data.Pclass == 1) & (all_data.Parch == 0) & (all_data.SibSp == 0)].Fare.dropna().median()\nfare_median_Pclass1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pclass=１の異常値を見つける\nfare_yijo_Pclass1 = all_data[(all_data.Fare > (fare_median_Pclass1*2)) & (all_data.Pclass == 1)] \nfare_yijo_Pclass1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. 異常Fareの中、PclassごとにFareが同じの人をgroupbyする "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pclass 3の場合\nfare_group_3 = fare_yijo_Pclass3.groupby(['Fare'])['Name'].count().reset_index()\nfare_group_3.rename({'Name': 'group_size'}, axis=1, inplace=True)\nfare_yijo_Pclass3 = fare_yijo_Pclass3.merge(fare_group_3, on='Fare').copy()\nfare_yijo_Pclass3.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pclass 2の場合\nfare_group_2 = fare_yijo_Pclass2.groupby(['Fare'])['Name'].count().reset_index()\nfare_group_2.rename({'Name': 'group_size'}, axis=1, inplace=True)\nfare_yijo_Pclass2 = fare_yijo_Pclass2.merge(fare_group_2, on='Fare').copy()\nfare_yijo_Pclass2.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pclass 1の場合\nfare_group_1 = fare_yijo_Pclass1.groupby(['Fare'])['Name'].count().reset_index()\nfare_group_1.rename({'Name': 'group_size'}, axis=1, inplace=True)\nfare_yijo_Pclass1 = fare_yijo_Pclass1.merge(fare_group_1, on='Fare').copy()\nfare_yijo_Pclass1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fare_error = pd.concat([fare_yijo_Pclass1, fare_yijo_Pclass2, fare_yijo_Pclass3], copy=True)\nfare_error.drop_duplicates(subset=['Fare', 'Pclass'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = all_data.merge(fare_error, on=['Fare', 'Pclass'], how='left', suffixes=('', '_drop'))\ndrop_col = all_data.filter(regex='.*_drop', axis=1)\nall_data.drop(columns=list(drop_col.columns), inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.group_size.fillna(1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots()\ndata = all_data[~all_data['Survived'].isna()]\nx = data.group_size.unique().tolist()\ny_all = data.group_size.value_counts().values.tolist()\ny_survi = data.groupby('group_size').Survived.sum().values.tolist()\nlabels = x\n\nax.bar(x, y_all, tick_label=labels, label='died')\nax.bar(x, y_survi, label='survived')\nax.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for a, b, c in zip(x,y_survi,y_all):\n    print(a,':', b/c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#グループサイズを分類\ngroupDf=pd.DataFrame()\n#groupDf['group_size']=all_data['group_size']\ngroupDf['Group_Small']=all_data['group_size'].map(lambda s : 1 if s <= 2 else 0)\ngroupDf['Group_Middle1'] =all_data['group_size'].map(lambda s : 1 if 3 <= s <= 4 else 0)\ngroupDf['Group_Middle2'] =all_data['group_size'].map(lambda s : 1 if 5 <= s <= 8 else 0)\ngroupDf['Group_Large'] =all_data['group_size'].map(lambda s : 1 if 9 <= s else 0)\ngroupDf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data=pd.concat([all_data,groupDf],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.drop('group_size',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#all_data[(all_data.Pclass == 3) & (all_data.Embarked == 'S') & (all_data.Parch == 0) & (all_data.SibSp == 0) & (all_data.Fare < 10)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fare_mean2 = all_data[(all_data.Pclass == 3) & (all_data.Embarked == 'S') & (all_data.Parch == 0) & (all_data.SibSp == 0) & (all_data.Fare < 10)].Fare.dropna().mean()\n#fare_mean2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#all_data['lastname'] = all_data.Name.str.split(',').map(lambda x: x[0]).str.strip()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#all_data['cabin_count'] = all_data[~all_data.Cabin.isna()].Cabin.str.split(' ').map(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#notna_cabin = all_data[~all_data.Cabin.isna()]\n#sns.distplot(notna_cabin.Fare)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fare, Pclass, cabin_countを利用してCabinタイプを推測するモデルを作って欠損値を設定\n#sub_cabin = all_data[['Cabin', 'Fare', 'Pclass', 'cabin_count']].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sub_cabin_train = sub_cabin[~sub_cabin.Cabin.isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sub_cabin_pred = sub_cabin[sub_cabin.Cabin.isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pattern = r'(\\[A-G])\\d'\n#result = re.match(pattern, string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sub_cabin_train.Cabin.str.split(' ').map(lambda x: x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 性別を数字化"},{"metadata":{"trusted":true},"cell_type":"code","source":"sex_mapDict={'male':1,'female':0}\nall_data['Sex']=all_data['Sex'].map(sex_mapDict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 乗船港をダミー化"},{"metadata":{"trusted":true},"cell_type":"code","source":"embarkedDf=pd.DataFrame()\nembarkedDf=pd.get_dummies(all_data['Embarked'],prefix='Embarked')\nembarkedDf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data=pd.concat([all_data,embarkedDf],axis=1)\nall_data.drop('Embarked',axis=1,inplace=True)\nall_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pclass（客室クラス）をダミー化"},{"metadata":{"trusted":true},"cell_type":"code","source":"pclassDf=pd.DataFrame()\npclassDf=pd.get_dummies(all_data['Pclass'],prefix='Pclass')\npclassDf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data=pd.concat([all_data,pclassDf],axis=1)\nall_data.drop('Pclass',axis=1,inplace=True)\nall_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Nameのタイトルをまとめる"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nname1='Braund, Mr. Owen Harris'\nstr1=name1.split(',')[1]\n#Mr.\nstr2=str1.split('.')[0]\nstr3=str2.strip()\n\ndef getTitle(name):\n    str1=name.split(',')[1]\n    str2=str1.split('.')[0]\n    str3=str2.strip()\n    \n    return str3\ntitleDf =pd.DataFrame()\ntitleDf['Title']=train_data['Name'].map(getTitle)\ntitleDf.head()\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title_mapDict={\n    \"Capt\":  \"Officer\",\n    \"Col\":  \"Officer\",\n    \"Major\": \"Officer\",\n    \"Jonkheer\":\"Royalty\",\n    \"Don\":\"Royalty\",\n    \"Sir\":\"Royalty\",\n    \"Dr\":\"Officer\",\n    \"Rev\":\"Officer\",\n    \"the countess\":\"Royalty\",\n    \"Dona\": \"Royalty\",\n    \"Mme\":\"Mrs\",\n    \"Mlle\":\"Miss\",\n    \"Ms\":\"Mrs\",\n    \"Mr\":\"Mr\",\n    \"Mrs\":\"Mrs\",\n    \"Miss\":\"Miss\",\n    \"Master\":\"Master\",\n    \"Lady\":\"Royalty\"\n              }\nall_data['Title']=all_data.title.map(title_mapDict)\ntitleDf=pd.get_dummies(all_data['Title'])\ntitleDf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data=pd.concat([all_data, titleDf], axis=1)\nall_data.drop(['Name', 'title', 'Title'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfamilyDf=pd.DataFrame()\nfamilyDf['FamilySize']=all_data['Parch']+ all_data['SibSp']+1\nfamilyDf['Family_Single']=familyDf['FamilySize'].map(lambda s : 1 if s == 1 else 0)\nfamilyDf['Family_Small'] =familyDf['FamilySize'].map(lambda s : 1 if 2 <= s <= 4 else 0)\nfamilyDf['Family_Large'] =familyDf['FamilySize'].map(lambda s : 1 if 5 <= s else 0)\nfamilyDf.head()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#all_data=pd.concat([all_data,familyDf],axis=1)\n#all_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#all_data.drop('Cabin',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#all_data=pd.concat([all_data, groupDf], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrDf_train=all_data.corr()\ncorrDf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrDf_train['Survived'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntree_df = all_data.drop(['PassengerId','Embarked_Q'], axis=1).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_train_df = tree_df[~tree_df.Survived.isna()]\ntree_test_df = tree_df[tree_df.Survived.isna()].drop('Survived', axis=1).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_test_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_col = list(tree_train_df.columns)\nX_col.remove('Survived')\nX_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = tree_train_df.columns.tolist()\nx.remove('Survived')\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_train_X = tree_train_df[x]\nprint(tree_train_X.shape)\ntree_train_Y = tree_train_df['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"tree_train_X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_train_X, t_test_X, t_train_y, t_test_y=train_test_split(tree_train_X, tree_train_Y, train_size=.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_train_X.shape, t_test_X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ランダムフォレストモデルを作成"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest=RandomForestClassifier(random_state=1234, min_samples_leaf=5, min_samples_split=10, n_estimators=500)\nparameters = {\n    'max_features':[0.2,0.3,0.4,0.5], \n    'max_leaf_nodes':[10,50,100,200], \n    'criterion':['gini', 'entropy']\n}\nclf = GridSearchCV(random_forest, parameters, n_jobs=4)\nclf.fit(X=t_train_X, y=t_train_y)\nrandom_forest = clf.best_estimator_\nprint (clf.best_score_, clf.best_params_) \n\n\n\n\n\n#random_forest.fit(t_train_X, t_train_y)\nt_test_pred = random_forest.predict(t_test_X)\nfpr, tpr, thresholds = roc_curve(t_test_y, t_test_pred, pos_label=1)\nprint(roc_auc_score(t_test_y, t_test_pred))\n#accuracy_score(t_test_pred, t_test_y)\nplt.clf()\nplt.plot(fpr, tpr)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_Y = random_forest.predict(tree_test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 決定木モデルを作成"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''parameters = {'max_depth':range(3,20)}\nclf = GridSearchCV(tree.DecisionTreeClassifier(), parameters, n_jobs=4)\nclf.fit(X=t_train_X, y=t_train_y)\ntree_model = clf.best_estimator_\nprint (clf.best_score_, clf.best_params_) '''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''predictions = tree_model.predict_proba(t_test_X)\n\nprint(roc_auc_score(t_test_y, predictions[:,1]))\n\nfpr, tpr, _ = roc_curve(t_test_y, predictions[:,1])\n\nplt.clf()\nplt.plot(fpr, tpr)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC curve')\nplt.show()'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pred_Y = tree_model.predict(tree_test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_Y=pred_Y.astype(int)\npassenger_id = all_data.loc[all_data.Survived.isna(), 'PassengerId']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predDF = pd.DataFrame(\n    {\n        'PassengerId': passenger_id,\n        'Survived': pred_Y\n    }\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predDF.to_csv('titanic_pred.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nfull_data_X=pd.concat([titleDf,\n                       pclassDf,\n                       familyDf,\n                       train_data['Fare'],\n                       embarkedDf,\n                       train_data['Sex'],\n                       train_data['Parch']\n                       ],axis=1)\nfull_data_X.head()\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#titleDf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#full_data_X.shape\n#train_data_X = full_data_X.loc[0:890, :]\n#pred_X = full_data_X.loc[891:,:]\n#train_data_Y = train_data.loc[0:890, 'Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pred_X['Fare']=pred_X['Fare'].fillna(full_data_X['Fare'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pred_X.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_X, test_X, train_y, test_y=train_test_split(train_data_X, train_data_Y, train_size=.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.linear_model import LogisticRegression\n#model=LogisticRegression()\n#model.fit(train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.score(test_X, test_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pred_Y = model.predict(pred_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pred_Y=pred_Y.astype(int)\n#passenger_id = train_data.loc[891:, 'PassengerId']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\npredDF = pd.DataFrame(\n    {\n        'PassengerId': passenger_id,\n        'Survived': pred_Y\n    }\n)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predDF.to_csv('titanic_pred.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#top_title = all_data[all_data.title.isin(list(all_data[all_data.Age.isnull()].title.value_counts().index))]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}